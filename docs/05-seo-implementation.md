# SEO Implementation & Strategy - The Savage Report

## What This Is & Why It Matters
We implemented foundational SEO across The Savage Report to help search engines understand the site quickly, index the right pages, and present high-quality results that drive traffic and sales.

## SEO Implementation Summary

| Item | What We Delivered | Impact | Status | Reference Link(s) |
|------|-------------------|--------|--------|-------------------|
| [Structured Data (Schema Markup)](#structured-data-schema-markup) | JSON-LD for Product, Organization, Local Business, and Website | High | âœ… Active | [Schema Markup Doc](./05.1-seo-schema.md) |
| [SEO-Optimized Content & Metadata](#seo-optimized-content--metadata) | Brand-consistent titles, descriptions, Open Graph tags, optimized URL slugs | High | âœ… Active | <a href="https://webflow.com/dashboard/sites/savage-report-we/designer" target="_blank" rel="noopener noreferrer">Webflow Designer</a> |
| [Technical SEO](#technical-seo) | XML sitemap, robots.txt, canonicals, HTTPS, site architecture improvements | High | âœ… Active | <a href="https://the-savage-report.com/sitemap.xml" target="_blank" rel="noopener noreferrer">Sitemap</a> Â· <a href="https://the-savage-report.com/robots.txt" target="_blank" rel="noopener noreferrer">Robots.txt</a> |
| [Mobile & Performance](#mobile--performance) | Mobile layout improvements and Core Web Vitals optimization | Medium | âœ… Active | <a href="https://pagespeed.web.dev/report?url=https://the-savage-report.com" target="_blank" rel="noopener noreferrer">PageSpeed Insights</a> Â· [Performance Doc](./06-page-speed-optimization.md) |
| [Robots.txt Configuration](#robots-txt-configuration) | Dual setup: Webflow main site + Shopify subdomain for optimal crawling | High | âœ… Active | <a href="https://the-savage-report.com/robots.txt" target="_blank" rel="noopener noreferrer">Webflow robots.txt</a> Â· <a href="https://shop.the-savage-report.com/robots.txt" target="_blank" rel="noopener noreferrer">Shopify robots.txt</a> |

> See also: ðŸ“š [XML Sitemap Management](../knowledge-hub/seo/xml-sitemap-management.md)

## What We Implemented

### Structured Data (Schema Markup)
- Prepared JSON-LD for Product, Organization, Local Business, and Website
- Currently inactive to avoid conflicts with the performance optimizer; ready to enable after compatibility validation
- Goal: enable rich results (stars, price, brand info) without compromising speed

### SEO-Optimized Content & Metadata
- Added SEO text blocks on collection pages (human-first, keyword-informed)
- Implemented consistent, brand-first meta titles and optimized descriptions
- Added Open Graph tags for improved social sharing
- Standardized URL slugs using best practices

### Technical SEO
- Enabled and verified auto XML sitemap
- Configured robots.txt for efficient crawling (verified in GSC)
- Implemented self-referencing canonicals sitewide
- Ensured HTTPS across domains with proper www/non-www handling
- Improved site architecture ("Shop All" index, optimized CMS collections, staged non-core pages)

### Mobile & Performance
- Mobile layout improvements (e.g., simplified homepage header for speed)
- Core Web Vitals improved with performance work (see performance doc)

## Robots.txt Configuration

### Dual Setup Overview
We have two separate robots.txt files that work independently:

1. **Webflow Main Site** (`the-savage-report.com/robots.txt`) - Controls crawling for your main website content
2. **Shopify Subdomain** (`shop.the-savage-report.com/robots.txt`) - Controls crawling for checkout/cart pages (auto-generated by Shopify)

### Webflow Robots.txt (Main Site)
This is the primary robots.txt that controls crawling for your main website content, products, and collections.

```txt
# THE SAVAGE REPORT - Robots.txt
# Website: https://the-savage-report.com
# Last Updated: August 2025

# Main crawler directives
User-agent: *
Allow: /

# Core pages - explicitly allow
Allow: /about
Allow: /contact
Allow: /newdrops
Allow: /policies/
Allow: /policies/privacy-policy
Allow: /policies/terms-of-service
Allow: /policies/refund-policy
Allow: /policies/shipping-returns

# Collections - allow indexing
Allow: /product/
Allow: /collection/
Allow: /vendor/
Allow: /lookbooks/
Allow: /campaigns/
Allow: /special-projects/

# Prevent duplicate content from filters/sorting
Disallow: /*?*sort=
Disallow: /*?*filter=
Disallow: /*?*page=
Disallow: /*?*size=
Disallow: /*?*color=
Disallow: /*?*price=
Disallow: /*?*view=
Disallow: /search?

# Block utility pages
Disallow: /401
Disallow: /style-guide

# Block draft/unpublished pages
Disallow: /shop
Disallow: /lookbook
Disallow: /special-project

# Googlebot-specific (for better crawl budget)
User-agent: Googlebot
Allow: /
Crawl-delay: 0

# Aggressive bot management
User-agent: AhrefsBot
Crawl-delay: 10

User-agent: SemrushBot
Crawl-delay: 10

User-agent: DotBot
Crawl-delay: 10

User-agent: MJ12bot
Crawl-delay: 15

# Block unwanted bots
User-agent: PetalBot
Disallow: /

User-agent: AspiegelBot
Disallow: /

User-agent: DataForSeoBot
Disallow: /

# Sitemap locations
Sitemap: https://the-savage-report.com/sitemap.xml
```

### Shopify Robots.txt (Subdomain)
Shopify automatically generates a robots.txt for your subdomain. It's optimized for e-commerce and includes:
- Allow crawling of product pages and collections
- Block admin areas and checkout pages
- Include sitemap reference

### Why This Dual Setup Works
- **Main site control**: Webflow robots.txt gives you full control over main site crawling
- **E-commerce optimization**: Shopify's auto-generated robots.txt is optimized for product discovery
- **No conflicts**: Each robots.txt only controls its respective domain
- **SEO benefits**: Both are configured for optimal search engine crawling

### Verification & Testing
- **Webflow robots.txt**: Verified in [Google Search Console](https://search.google.com/search-console/settings/robots-txt?resource_id=sc-domain:the-savage-report.com)
- **Shopify robots.txt**: Automatically managed by Shopify
- **Both working**: Search engines can access both sites without conflicts

## XML Sitemap Implementation

### Sitemap Summary
- **Total URLs**: 61
- **Static Pages**: 8 (Home, About, Contact, Newdrops, Policies)
- **Collection Pages**: 6 (Accessories, All Products, Hats, Pants, Shirts, T-Shirts)
- **Product Pages**: 46 individual products
- **Auto-generated**: Yes, by Webflow CMS
- **Last Updated**: Automatically updated when content changes

### Sitemap Management
- **Location**: https://www.the-savage-report.com/sitemap.xml
- **Google Search Console**: Verified and indexed
- **Auto-updates**: New products and collections automatically added
- **SEO Impact**: Helps search engines discover and index all content efficiently

## Site Architecture (At a Glance)
```
Customers â†’ Webflow (Pages, CMS) â†’ Smootify (Bridge) â†’ Shopify (Products, Orders)
                           â†˜ XML Sitemap / robots.txt â†™      
```

## Core Web Vitals Snapshot
- Track with PageSpeed Insights (mobile/desktop) and internal monitoring
- Key metrics: LCP < 2.5s, CLS < 0.1, INP < 200ms
- Evidence: [PSI Report](https://pagespeed.web.dev/report?url=https://the-savage-report.com)

## Sitemaps in Google Search Console (Admin Reference)
This is where you can review and manage sitemap status over time (status, last read, discovered URLs). After publishing significant changes, revisit this page to resubmit if needed.

<img src="../assets/seo-implementation-gsc-sitemaps-2025-08-08.png" alt="GSC submitted sitemap view" width="70%" style="border-radius:8px" />

- **Open**: [GSC Sitemaps](https://search.google.com/search-console/sitemaps?resource_id=sc-domain:the-savage-report.com)

## Webflow SEO Settings (By Topic)

### Custom Code & Scripts
Configure custom code and scripts for SEO enhancements like schema markup and tracking codes.

<img src="../assets/seo-implementation-webflow-seo-settings-01.png" alt="Custom Code settings in Webflow" width="70%" style="border-radius:8px" />

- **Purpose**: Configure custom code and scripts for SEO enhancements
- **Location**: [Webflow â†’ Custom Code](https://webflow.com/dashboard/sites/savage-report-we/custom-code)

### Sitemap Configuration
Configure automatic sitemap generation when site is published for better search engine indexing.

<img src="../assets/seo-implementation-webflow-seo-settings-02.png" alt="Sitemap configuration in Webflow" width="70%" style="border-radius:8px" />

- **Purpose**: Configure automatic sitemap generation when site is published
- **Location**: [Webflow â†’ SEO Settings](https://webflow.com/dashboard/sites/savage-report-we/seo)

### Google Site Verification
Verify site ownership with Google Search Console for access to search data and analytics.

<img src="../assets/seo-implementation-webflow-seo-settings-03.png" alt="Google site verification in Webflow" width="70%" style="border-radius:8px" />

- **Purpose**: Verify site ownership with Google Search Console for access to search data
- **Location**: [Webflow â†’ SEO Settings](https://webflow.com/dashboard/sites/savage-report-we/seo)

### Robots.txt & Canonical
Control search engine crawling behavior and set global canonical URL to prevent duplicate content.

<img src="../assets/seo-implementation-webflow-seo-settings-04.png" alt="robots.txt configuration with canonical URL and traffic controls" width="70%" style="border-radius:8px" />

- **Purpose**: Control search engine crawling behavior and set global canonical URL
- **Configuration**: Global canonical URL set to `https://www.the-savage-report.com`
- **Links**: [robots.txt](https://the-savage-report.com/robots.txt) Â· [GSC Robots Tester](https://search.google.com/search-console/settings/robots-txt?resource_id=sc-domain:the-savage-report.com)

### Traffic Controls
Control access for search engine crawlers and AI bots to manage site traffic and indexing.

<img src="../assets/seo-implementation-webflow-seo-settings-05.png" alt="Traffic controls for search engines and AI bots" width="70%" style="border-radius:8px" />

- **Purpose**: Control access for search engine crawlers and AI bots
- **Configuration**: Both search engines and AI bots are allowed access

### Publishing
After changes, publish the site so updates go live; then verify in GSC/PSI.

<img src="../assets/seo-implementation-webflow-seo-settings-06.png" alt="Publishing changes in Webflow" width="70%" style="border-radius:8px" />

- **Purpose**: Deploy SEO changes to live site
- **Links**: [Publish in Webflow](https://webflow.com/dashboard/sites/savage-report-we) Â· [PSI Report](https://pagespeed.web.dev/report?url=https://the-savage-report.com)

